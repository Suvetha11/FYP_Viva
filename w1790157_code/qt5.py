# -*- coding: utf-8 -*-
"""QT5.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sJfilhhi3rWKtaYy5Sokyxx6AjtarICf
"""

!pip install transformers
!pip install sentencepiece

from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW
import pandas as pd
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import torch

from google.colab import drive
drive.mount('/content/drive')

# Load the dataset
df = pd.read_csv("https://raw.githubusercontent.com/Suvetha11/FYP-Dataset/main/data/dataset.csv")
input_code = df['command'].values.tolist()
output_description = df['code'].values.tolist()

# Split the dataset into train and validation sets
train_input, val_input, train_output, val_output = train_test_split(input_code, output_description, test_size=0.1, random_state=42)

# Tokenize the dataset
tokenizer = T5Tokenizer.from_pretrained('t5-small')
train_encodings = tokenizer(train_input, padding=True, truncation=True)
train_labels = tokenizer(train_output, padding=True, truncation=True)
val_encodings = tokenizer(val_input, padding=True, truncation=True)
val_labels = tokenizer(val_output, padding=True, truncation=True)



# Define the dataset
class T5Dataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels['input_ids'][idx])
        return item

    def __len__(self):
        return len(self.encodings['input_ids'])

# Create the dataloaders
train_dataset = T5Dataset(train_encodings, train_labels)
val_dataset = T5Dataset(val_encodings, val_labels)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

# Instantiate the model and optimizer
model = T5ForConditionalGeneration.from_pretrained('/content/drive/MyDrive/T5-model')
optimizer = AdamW(model.parameters(), lr=3e-5)

# Define the new tokens to add to the vocabulary
new_tokens = ["<"]

# Add the new tokens to the tokenizer vocabulary
tokenizer.add_tokens(new_tokens)

# Update the T5 model to use the new vocabulary
model.resize_token_embeddings(len(tokenizer))


# Define the training loop
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

epochs = 30
for epoch in range(epochs):
    model.train()
    for batch in train_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        optimizer.zero_grad()
        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs.loss
        loss.backward()
        optimizer.step()

    model.eval()
    total_val_loss = 0
    for batch in val_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        with torch.no_grad():
            outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)
            val_loss = outputs.loss
            total_val_loss += val_loss.item()

    print(f"Epoch {epoch + 1}: val_loss={total_val_loss / len(val_loader)}")

from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW
import pandas as pd
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import torch

from google.colab import drive
drive.mount('/content/drive')

tokenizer = T5Tokenizer.from_pretrained('t5-small')

# Load the model from Google Drive

load_model = T5ForConditionalGeneration.from_pretrained('/content/drive/MyDrive/T5-b10-model16')

input_text = "declare integer x with value five"
input_ids = tokenizer.encode(input_text, return_tensors="pt")
outputs = load_model.generate(input_ids, max_new_tokens=100000)
output_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
print(output_text)

#Evaluation

from transformers import T5Tokenizer, T5ForConditionalGeneration
from sklearn.metrics import confusion_matrix
from sklearn.metrics import roc_auc_score
import torch

# Load the tokenizer and model
tokenizer = T5Tokenizer.from_pretrained('t5-small')
model = T5ForConditionalGeneration.from_pretrained('/content/drive/MyDrive/T5-b10-model16')

# Load the evaluation dataset
eval_dataset = pd.read_csv("https://raw.githubusercontent.com/Suvetha11/FYP-Dataset/main/data/testdataset.csv")
input_text = eval_dataset['command'].values.tolist()
target_text = eval_dataset['code'].values.tolist()
# Create an empty list to store the model outputs
model_outputs = []

# Generate outputs for each input in the evaluation dataset
for i in range(len(input_text)):
    input_ids = tokenizer.encode(input_text[i], return_tensors='pt')
    output_ids = model.generate(input_ids, max_new_tokens=100000)
    output_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)
    model_outputs.append(output_text)

# Calculate the accuracy
num_correct = 0
num_total = len(input_text)
for i in range(len(input_text)):
    if model_outputs[i] == target_text[i]:
        num_correct += 1
accuracy = num_correct / num_total
print(accuracy*100)
print(f'Accuracy: {accuracy:.4f}')

from sklearn.metrics import classification_report
from sklearn.preprocessing import LabelEncoder

# Instantiate LabelEncoder
label_encoder = LabelEncoder()

# Fit LabelEncoder on all labels
all_labels = set(target_text).union(set(model_outputs))
label_encoder.fit(list(all_labels))

# Convert true and predicted labels to numerical form
true_labels = label_encoder.transform(target_text)
predicted_labels = label_encoder.transform(model_outputs)

# Print classification report
report = classification_report(true_labels, predicted_labels, target_names=label_encoder.classes_)
print(report)